# RAG-Based Academic Tutor

A comprehensive Retrieval-Augmented Generation (RAG) system for academic document Q&A, featuring multiple chunking strategies, vector embeddings, and Mistral-7B integration with a Streamlit interface.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Document      â”‚â”€â”€â”€â–¶â”‚   Processing    â”‚â”€â”€â”€â–¶â”‚   Vector        â”‚
â”‚   Ingestion     â”‚    â”‚   & Chunking    â”‚    â”‚   Storage       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚   (ChromaDB)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚â—€â”€â”€â”€â”‚   RAG Chain     â”‚â—€â”€â”€â”€â”‚   Retrieval     â”‚
â”‚                 â”‚    â”‚   Orchestrator  â”‚    â”‚   Engine        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Mistral-7B    â”‚
                       â”‚   Generation    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

### **Document Processing**
- **Multi-format support**: Text files (.txt)
- **Advanced chunking**: Sliding window, paragraph boundary, semantic chunking
- **Text preprocessing**: Whitespace normalization, encoding fixes, citation cleanup

### **Retrieval System**
- **Vector embeddings**: Sentence-transformers integration
- **Vector database**: ChromaDB with persistent storage
- **Similarity search**: Configurable top-k retrieval

### **Language Model**
- **Mistral-7B-Instruct-v0.3**: State-of-the-art instruction-tuned model
- **Mock model support**: For testing and development
- **Optimized inference**: Float16 precision, device mapping

### **User Interface**
- **Streamlit web app**: Interactive chat interface
- **Real-time processing**: Stream responses
- **Session management**: Persistent chat history

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (recommended for Mistral-7B)
- 8GB+ GPU memory (16GB+ recommended)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/rag-academic-tutor
   cd rag-academic-tutor
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Run the application**
   ```bash
   streamlit run main.py
   ```

## ğŸ’¡ Usage

### **Basic Q&A**
1. Launch the Streamlit app: `streamlit run main.py`
2. Upload academic documents via the interface
3. Ask questions about your documents
4. Get contextual answers with source references

### **Programmatic Usage**
```python
from src.generation.rag_chain import RAGChain

# Initialize RAG system
rag = RAGChain(
    persist_directory="./data/chromadb",
    collection_name="my_docs"
)

# Ask questions
response = rag.ask("What is the main hypothesis of this paper?")
print(response.answer)
print(f"Sources: {len(response.source_documents)} documents")
```

## âš™ï¸ Configuration

### **Model Options**
- **Development**: Use `MockModel` for testing
- **Production**: Use `mistralai/Mistral-7B-Instruct-v0.3`

### **Chunking Strategies**
- `sliding_window`: Fixed-size chunks with overlap
- `paragraph_boundary`: Respects paragraph structure  
- `semantic`: Topic-aware chunking

### **Testing**
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src

# Run specific test file
pytest test/ingestion/test_document.py -v
```

## ğŸ“ Project Structure

```
rag-academic-tutor/
â”œâ”€â”€ main.py                 # Streamlit application entry point
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ pytest.ini            # Test configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/         # Document processing & chunking
â”‚   â”‚   â”œâ”€â”€ document.py    # Document loading
â”‚   â”‚   â”œâ”€â”€ chunker.py     # Text chunking strategies
â”‚   â”‚   â”œâ”€â”€ embedding.py   # Embedding models
â”‚   â”‚   â””â”€â”€ preprocessor.py # Text cleaning
â”‚   â”œâ”€â”€ retrieval/         # Vector search & retrieval
â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â””â”€â”€ generation/        # LLM integration & response generation
â”‚       â”œâ”€â”€ rag_chain.py   # RAG orchestrator
â”‚       â”œâ”€â”€ llm_client.py  # Mistral-7B client
â”‚       â””â”€â”€ prompt_template.py
â”œâ”€â”€ test/                  # Test suite
â”œâ”€â”€ data/                  # Data storage
â”‚   â””â”€â”€ chromadb/         # Vector database
â””â”€â”€ docs/                  # Documentation
```

## ğŸ”§ Technical Implementation

### **Key Technologies**
- **Language Model**: Mistral-7B-Instruct-v0.3
- **Embeddings**: Sentence-transformers
- **Vector Database**: ChromaDB  
- **Web Framework**: Streamlit
- **ML Framework**: PyTorch + Transformers

### **Performance Optimizations**
- Float16 precision for memory efficiency
- Automatic device mapping for GPU utilization
- Persistent vector storage with ChromaDB
- Configurable chunking for optimal context

## AI Tools Disclaimer

During the development of this project we are limiting the use of AI tools 
to research only. The code in this repository has been organically grown. 
